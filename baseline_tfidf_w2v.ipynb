{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "adbbc2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lorraine/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/lorraine/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/lorraine/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject take advantage low interest  rates  no...</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject lowest rate us history sound  let 6000...</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject application pre  approved monday oct 1...</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject final offer wed  29 sep 2004 19  16  0...</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject application confirmation sun  14 nov 2...</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>subject popular software low low prices  bury ...</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>subject clean ur computer 3 ey 85  chance comp...</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>subject software incredibly low prices  73  lo...</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>subject latest qem software available  low pri...</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>subject cnet reviews  results favorite program...</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2182 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence           label\n",
       "0     subject take advantage low interest  rates  no...   insurance-etc\n",
       "1     subject lowest rate us history sound  let 6000...   insurance-etc\n",
       "2     subject application pre  approved monday oct 1...   insurance-etc\n",
       "3     subject final offer wed  29 sep 2004 19  16  0...   insurance-etc\n",
       "4     subject application confirmation sun  14 nov 2...   insurance-etc\n",
       "...                                                 ...             ...\n",
       "2177  subject popular software low low prices  bury ...  software-sales\n",
       "2178  subject clean ur computer 3 ey 85  chance comp...  software-sales\n",
       "2179  subject software incredibly low prices  73  lo...  software-sales\n",
       "2180  subject latest qem software available  low pri...  software-sales\n",
       "2181  subject cnet reviews  results favorite program...  software-sales\n",
       "\n",
       "[2182 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import re\n",
    "def cleaning(sentence):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = re.sub(r'[^\\w\\s]', '', sentence.lower()).replace(\"\\n\", \" \").split(\" \")\n",
    "    cleaned = [token for token in tokens if token not in stop_words]\n",
    "    return \" \".join(cleaned)\n",
    "labels = [\"insurance-etc\",\"investment\", \"medical-sales\", \"phising\", \"sexual\", \"software-sales\"]\n",
    "text = []\n",
    "classes = []\n",
    "for label in labels:\n",
    "    path = \"/Users/lorraine/Desktop/Spam_Filter/Annotated/\"+label\n",
    "  \n",
    "    os.chdir(path)\n",
    "  \n",
    "    def read_text_file(file_path):\n",
    "        with open(file_path, 'r', encoding='ISO-8859-1') as f:\n",
    "            return f.read()\n",
    "      \n",
    "    for file in os.listdir():\n",
    "    \n",
    "        if file.endswith(\".txt\"):\n",
    "            file_path = f\"{path}/{file}\"\n",
    "            text.append(cleaning(str(read_text_file(file_path))))\n",
    "            classes.append(label)\n",
    "\n",
    "data = pd.DataFrame({'sentence':text, 'label':classes})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3444b1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "932b7945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(word):\n",
    "    sentence = data['sentence']\n",
    "    idf = np.log(len(sentence)/sentence.str.contains(word).sum())\n",
    "    result = []\n",
    "    for i in range(len(sentence)):\n",
    "        tf = sentence.iloc[i].count(word)/(len(sentence.iloc[i]))\n",
    "        result.append(tf*idf)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a7bf0907",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gr/mx83vpvn7z713f1dzv81v63r0000gn/T/ipykernel_25696/3118394667.py:3: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  idf = np.log(len(sentence)/sentence.str.contains(word).sum())\n",
      "/var/folders/gr/mx83vpvn7z713f1dzv81v63r0000gn/T/ipykernel_25696/3118394667.py:7: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result.append(tf*idf)\n",
      "/var/folders/gr/mx83vpvn7z713f1dzv81v63r0000gn/T/ipykernel_25696/3118394667.py:3: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  idf = np.log(len(sentence)/sentence.str.contains(word).sum())\n",
      "/var/folders/gr/mx83vpvn7z713f1dzv81v63r0000gn/T/ipykernel_25696/3118394667.py:7: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result.append(tf*idf)\n",
      "/var/folders/gr/mx83vpvn7z713f1dzv81v63r0000gn/T/ipykernel_25696/3118394667.py:3: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  idf = np.log(len(sentence)/sentence.str.contains(word).sum())\n",
      "/var/folders/gr/mx83vpvn7z713f1dzv81v63r0000gn/T/ipykernel_25696/3118394667.py:7: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result.append(tf*idf)\n",
      "/var/folders/gr/mx83vpvn7z713f1dzv81v63r0000gn/T/ipykernel_25696/3118394667.py:3: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  idf = np.log(len(sentence)/sentence.str.contains(word).sum())\n",
      "/var/folders/gr/mx83vpvn7z713f1dzv81v63r0000gn/T/ipykernel_25696/3118394667.py:7: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result.append(tf*idf)\n",
      "/var/folders/gr/mx83vpvn7z713f1dzv81v63r0000gn/T/ipykernel_25696/3118394667.py:3: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  idf = np.log(len(sentence)/sentence.str.contains(word).sum())\n",
      "/var/folders/gr/mx83vpvn7z713f1dzv81v63r0000gn/T/ipykernel_25696/3118394667.py:7: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  result.append(tf*idf)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>insurance-etc</th>\n",
       "      <th>investment</th>\n",
       "      <th>medical-sales</th>\n",
       "      <th>phising</th>\n",
       "      <th>sexual</th>\n",
       "      <th>software-sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.032397</td>\n",
       "      <td>0.012083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007124</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.057250</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012809</td>\n",
       "      <td>0.006285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2182 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      insurance-etc  investment  medical-sales   phising    sexual  \\\n",
       "0          0.032397    0.012083       0.000000  0.000000  0.007124   \n",
       "1          0.057250    0.003857       0.000000  0.000000  0.000000   \n",
       "2          0.015594    0.000000       0.001352  0.000000  0.000000   \n",
       "3          0.012809    0.006285       0.000000  0.003700  0.000000   \n",
       "4          0.016872    0.000000       0.000000  0.000000  0.001902   \n",
       "...             ...         ...            ...       ...       ...   \n",
       "2177       0.000000    0.003636       0.000000  0.000000  0.000000   \n",
       "2178       0.000000    0.000000       0.003091  0.000000  0.000000   \n",
       "2179       0.000000    0.003785       0.002142  0.000000  0.000000   \n",
       "2180       0.000000    0.002509       0.000000  0.010853  0.000000   \n",
       "2181       0.000000    0.000000       0.000000  0.002518  0.000000   \n",
       "\n",
       "      software-sales  \n",
       "0           0.000000  \n",
       "1           0.000000  \n",
       "2           0.000000  \n",
       "3           0.017154  \n",
       "4           0.000000  \n",
       "...              ...  \n",
       "2177        0.003636  \n",
       "2178        0.000000  \n",
       "2179        0.003785  \n",
       "2180        0.051350  \n",
       "2181        0.010501  \n",
       "\n",
       "[2182 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "f = open('/Users/lorraine/Desktop/Spam_Filter/seedwords.json')\n",
    "seeds = json.load(f)\n",
    "result = pd.DataFrame()\n",
    "for key, value in seeds.items():\n",
    "    df = pd.DataFrame()\n",
    "    for w in value:\n",
    "        df[w] = tfidf(w)\n",
    "    result[key] = df.sum(axis = 1)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80c53b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject take advantage low interest  rates  no...</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject lowest rate us history sound  let 6000...</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject application pre  approved monday oct 1...</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject final offer wed  29 sep 2004 19  16  0...</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject application confirmation sun  14 nov 2...</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>subject popular software low low prices  bury ...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>investment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>subject clean ur computer 3 ey 85  chance comp...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>medical-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>subject software incredibly low prices  73  lo...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>investment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>subject latest qem software available  low pri...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>subject cnet reviews  results favorite program...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2182 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence           label  \\\n",
       "0     subject take advantage low interest  rates  no...   insurance-etc   \n",
       "1     subject lowest rate us history sound  let 6000...   insurance-etc   \n",
       "2     subject application pre  approved monday oct 1...   insurance-etc   \n",
       "3     subject final offer wed  29 sep 2004 19  16  0...   insurance-etc   \n",
       "4     subject application confirmation sun  14 nov 2...   insurance-etc   \n",
       "...                                                 ...             ...   \n",
       "2177  subject popular software low low prices  bury ...  software-sales   \n",
       "2178  subject clean ur computer 3 ey 85  chance comp...  software-sales   \n",
       "2179  subject software incredibly low prices  73  lo...  software-sales   \n",
       "2180  subject latest qem software available  low pri...  software-sales   \n",
       "2181  subject cnet reviews  results favorite program...  software-sales   \n",
       "\n",
       "          prediction  \n",
       "0      insurance-etc  \n",
       "1      insurance-etc  \n",
       "2      insurance-etc  \n",
       "3     software-sales  \n",
       "4      insurance-etc  \n",
       "...              ...  \n",
       "2177      investment  \n",
       "2178   medical-sales  \n",
       "2179      investment  \n",
       "2180  software-sales  \n",
       "2181  software-sales  \n",
       "\n",
       "[2182 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"prediction\"] = result.idxmax(1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ba42050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# micro and macro F1 using tf-idf\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b013429c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6585701191567369"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(data[\"label\"], data[\"prediction\"], average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1f00df97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6326503276247037"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(data[\"label\"], data[\"prediction\"], average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb39d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4ef2f1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "def preprocessing(sentence):\n",
    "    tokens = sentence.split(\" \")\n",
    "    return [token for token in tokens if token!=\"\" and token != \" \"]\n",
    "features = data[\"sentence\"].apply(preprocessing)\n",
    "model = Word2Vec(sentences=features, size=100, window=5, min_count=1, workers=4)\n",
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "600ed801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6195351, 6290560)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save(\"word2vec.model\")\n",
    "model = Word2Vec.load(\"word2vec.model\")\n",
    "model.train(features, total_examples=len(data), epochs=20)\n",
    "#vector = model.wv[\"atheism\"]\n",
    "#vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3dd44e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors_per_label(filename):\n",
    "    f = open(filename)\n",
    "    seeds = json.load(f)\n",
    "    vector_per_label = []\n",
    "    for key, value in seeds.items():\n",
    "        lst = []\n",
    "        for w in value:\n",
    "            lst.append(model.wv[w])\n",
    "        arr = np.asarray(lst)\n",
    "        total = np.average(arr, axis=0)\n",
    "        vector_per_label.append(total)\n",
    "    return vector_per_label\n",
    "vector_per_label = get_vectors_per_label('/Users/lorraine/Desktop/Spam_Filter/seedwords.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f18640f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2e7bcc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_per_doc(feature):\n",
    "    vector_per_doc = []\n",
    "    for feat in feature:\n",
    "        lst = []\n",
    "        for w in feat:\n",
    "            lst.append(model.wv[w])\n",
    "        arr = np.asarray(lst)\n",
    "        total = np.average(arr, axis=0)\n",
    "        vector_per_doc.append(total)\n",
    "    return vector_per_doc\n",
    "vector_per_doc = get_vector_per_doc(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "988a06a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2182"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector_per_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a89c5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d97daeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/Users/lorraine/Desktop/Spam_Filter/seedwords.json')\n",
    "seeds = json.load(f)\n",
    "from numpy.linalg import norm\n",
    "def predict_word2vec(vector_per_doc, vector_per_label):\n",
    "    predictions = []\n",
    "    labels = list(seeds.keys())\n",
    "    for doc in vector_per_doc:\n",
    "        cosine = []\n",
    "        for label in vector_per_label:\n",
    "            cosine.append(np.dot(doc,label)/(norm(doc)*norm(label)))\n",
    "        max_value = max(cosine)\n",
    "        max_index = cosine.index(max_value)\n",
    "        predictions.append(labels[max_index])\n",
    "    return predictions   \n",
    "prediction_word2vec = predict_word2vec(vector_per_doc, vector_per_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9e804645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prediction_word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject take advantage low interest  rates  no...</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject lowest rate us history sound  let 6000...</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject application pre  approved monday oct 1...</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>sexual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject final offer wed  29 sep 2004 19  16  0...</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject application confirmation sun  14 nov 2...</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>subject popular software low low prices  bury ...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>investment</td>\n",
       "      <td>medical-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>subject clean ur computer 3 ey 85  chance comp...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>medical-sales</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>subject software incredibly low prices  73  lo...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>investment</td>\n",
       "      <td>medical-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>subject latest qem software available  low pri...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>subject cnet reviews  results favorite program...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2182 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence           label  \\\n",
       "0     subject take advantage low interest  rates  no...   insurance-etc   \n",
       "1     subject lowest rate us history sound  let 6000...   insurance-etc   \n",
       "2     subject application pre  approved monday oct 1...   insurance-etc   \n",
       "3     subject final offer wed  29 sep 2004 19  16  0...   insurance-etc   \n",
       "4     subject application confirmation sun  14 nov 2...   insurance-etc   \n",
       "...                                                 ...             ...   \n",
       "2177  subject popular software low low prices  bury ...  software-sales   \n",
       "2178  subject clean ur computer 3 ey 85  chance comp...  software-sales   \n",
       "2179  subject software incredibly low prices  73  lo...  software-sales   \n",
       "2180  subject latest qem software available  low pri...  software-sales   \n",
       "2181  subject cnet reviews  results favorite program...  software-sales   \n",
       "\n",
       "          prediction prediction_word2vec  \n",
       "0      insurance-etc       insurance-etc  \n",
       "1      insurance-etc       insurance-etc  \n",
       "2      insurance-etc              sexual  \n",
       "3     software-sales       insurance-etc  \n",
       "4      insurance-etc       insurance-etc  \n",
       "...              ...                 ...  \n",
       "2177      investment       medical-sales  \n",
       "2178   medical-sales      software-sales  \n",
       "2179      investment       medical-sales  \n",
       "2180  software-sales      software-sales  \n",
       "2181  software-sales      software-sales  \n",
       "\n",
       "[2182 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"prediction_word2vec\"] = prediction_word2vec\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2f8b4d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.576076993583868"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# micro and macro F1 using word2vec\n",
    "metrics.f1_score(data[\"label\"], data[\"prediction_word2vec\"], average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "96cbe228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5703324192605602"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(data[\"label\"], data[\"prediction_word2vec\"], average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "163c1c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.576076993583868"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data[\"prediction_word2vec\"] == data[\"label\"])/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7559151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
