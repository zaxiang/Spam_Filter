{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adbbc2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Garrett\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Garrett\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Garrett\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\School\\DSC180\\Spam-Filter\\Spam_Filter\\Annotated\\insurance-etc\n",
      "E:\\School\\DSC180\\Spam-Filter\\Spam_Filter\\Annotated\\investment\n",
      "E:\\School\\DSC180\\Spam-Filter\\Spam_Filter\\Annotated\\medical-sales\n",
      "E:\\School\\DSC180\\Spam-Filter\\Spam_Filter\\Annotated\\phising\n",
      "E:\\School\\DSC180\\Spam-Filter\\Spam_Filter\\Annotated\\sexual\n",
      "E:\\School\\DSC180\\Spam-Filter\\Spam_Filter\\Annotated\\software-sales\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject  h  ello dea 54 r home owner  beetcn n...</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject make  171 hello  sent email ago  quali...</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject 96  refinance 2  9  hi would reflnance...</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject 82  refinance today  low 2  9  hey wou...</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject 6  refinance today premium low rate he...</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>subject  2   question soft mult gua msof  ilan...</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>subject  5   question progs mult gua msof  ila...</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>subject  7   talks soft mult gua msof  ilan ge...</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>subject dear sir  interested hi   need softwar...</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>__label__softwaresales subject coreldraw  100 ...</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence           label\n",
       "0     subject  h  ello dea 54 r home owner  beetcn n...   insurance-etc\n",
       "1     subject make  171 hello  sent email ago  quali...   insurance-etc\n",
       "2     subject 96  refinance 2  9  hi would reflnance...   insurance-etc\n",
       "3     subject 82  refinance today  low 2  9  hey wou...   insurance-etc\n",
       "4     subject 6  refinance today premium low rate he...   insurance-etc\n",
       "...                                                 ...             ...\n",
       "2235  subject  2   question soft mult gua msof  ilan...  software-sales\n",
       "2236  subject  5   question progs mult gua msof  ila...  software-sales\n",
       "2237  subject  7   talks soft mult gua msof  ilan ge...  software-sales\n",
       "2238  subject dear sir  interested hi   need softwar...  software-sales\n",
       "2239  __label__softwaresales subject coreldraw  100 ...  software-sales\n",
       "\n",
       "[2240 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn import metrics\n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import re\n",
    "def cleaning(sentence):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = re.sub(r'[^\\w\\s]', '', sentence.lower()).replace(\"\\n\", \" \").split(\" \")\n",
    "    cleaned = [token for token in tokens if token not in stop_words]\n",
    "    return \" \".join(cleaned)\n",
    "labels = [\"insurance-etc\",\"investment\", \"medical-sales\", \"phising\", \"sexual\", \"software-sales\"]\n",
    "text = []\n",
    "classes = []\n",
    "for label in labels:\n",
    "    path = os.getcwd()+\"\\\\Annotated\\\\\"+label\n",
    "    print(path)\n",
    "    os.chdir(path)\n",
    "    \n",
    "    def read_text_file(file_path):\n",
    "        with open(file_path, 'r', encoding='ISO-8859-1') as f:\n",
    "            return f.read()\n",
    "      \n",
    "    for file in os.listdir():\n",
    "    \n",
    "        if file.endswith(\".txt\"):\n",
    "            file_path = f\"{path}/{file}\"\n",
    "            text.append(cleaning(str(read_text_file(file_path))))\n",
    "            classes.append(label)\n",
    "    os.chdir(\"../..\")\n",
    "data = pd.DataFrame({'sentence':text, 'label':classes})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3444b1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b7945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(word):\n",
    "    sentence = data['sentence']\n",
    "    idf = np.log(len(sentence)/sentence.str.contains(word).sum())\n",
    "    result = []\n",
    "    for i in range(len(sentence)):\n",
    "        tf = sentence.iloc[i].count(word)/(len(sentence.iloc[i]))\n",
    "        result.append(tf*idf)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bf0907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open('seedwords.json')\n",
    "seeds = json.load(f)\n",
    "result = pd.DataFrame()\n",
    "for key, value in seeds.items():\n",
    "    df = pd.DataFrame()\n",
    "    for w in value:\n",
    "        df[w] = tfidf(w)\n",
    "    result[key] = df.sum(axis = 1)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c53b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"prediction\"] = result.idxmax(1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba42050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# micro and macro F1 using tf-idf\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b013429c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics.f1_score(data[\"label\"], data[\"prediction\"], average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(data[\"label\"], data[\"prediction\"], average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb39d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef2f1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "def preprocessing(sentence):\n",
    "    tokens = sentence.split(\" \")\n",
    "    return [token for token in tokens if token!=\"\" and token != \" \"]\n",
    "features = data[\"sentence\"].apply(preprocessing)\n",
    "model = Word2Vec(sentences=features, vector_size=100, window=5, min_count=1, workers=4)\n",
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600ed801",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec.model\")\n",
    "model = Word2Vec.load(\"word2vec.model\")\n",
    "model.train(features, total_examples=len(data), epochs=20)\n",
    "#vector = model.wv[\"atheism\"]\n",
    "#vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd44e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors_per_label(filename):\n",
    "    f = open(filename)\n",
    "    seeds = json.load(f)\n",
    "    vector_per_label = []\n",
    "    for key, value in seeds.items():\n",
    "        lst = []\n",
    "        for w in value:\n",
    "            lst.append(model.wv[w])\n",
    "        arr = np.asarray(lst)\n",
    "        total = np.average(arr, axis=0)\n",
    "        vector_per_label.append(total)\n",
    "    return vector_per_label\n",
    "vector_per_label = get_vectors_per_label('seedwords.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f18640f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7bcc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_per_doc(feature):\n",
    "    vector_per_doc = []\n",
    "    for feat in feature:\n",
    "        lst = []\n",
    "        for w in feat:\n",
    "            lst.append(model.wv[w])\n",
    "        arr = np.asarray(lst)\n",
    "        total = np.average(arr, axis=0)\n",
    "        vector_per_doc.append(total)\n",
    "    return vector_per_doc\n",
    "vector_per_doc = get_vector_per_doc(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a89c5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97daeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('seedwords.json')\n",
    "seeds = json.load(f)\n",
    "from numpy.linalg import norm\n",
    "def predict_word2vec(vector_per_doc, vector_per_label):\n",
    "    predictions = []\n",
    "    labels = list(seeds.keys())\n",
    "    for doc in vector_per_doc:\n",
    "        cosine = []\n",
    "        for label in vector_per_label:\n",
    "            cosine.append(np.dot(doc,label)/(norm(doc)*norm(label)))\n",
    "        max_value = max(cosine)\n",
    "        max_index = cosine.index(max_value)\n",
    "        predictions.append(labels[max_index])\n",
    "    return predictions   \n",
    "prediction_word2vec = predict_word2vec(vector_per_doc, vector_per_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e804645",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"prediction_word2vec\"] = prediction_word2vec\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8b4d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# micro and macro F1 using word2vec\n",
    "metrics.f1_score(data[\"label\"], data[\"prediction_word2vec\"], average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cbe228",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(data[\"label\"], data[\"prediction_word2vec\"], average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163c1c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data[\"prediction_word2vec\"] == data[\"label\"])/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e789bc-4fa3-4b1b-b1a9-83ab25cb2c4a",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7559151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-cf238e56559e>:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set['pred'] = preds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>subject   utf  8  q  take 1     utf  8  q  1 m...</td>\n",
       "      <td>medical-sales</td>\n",
       "      <td>medical-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>subject  dream lifestyle earlene  know actuall...</td>\n",
       "      <td>investment</td>\n",
       "      <td>medical-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>subject photoshop  windows  office  cheap  bro...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>subject dr ndeye desk dr  mohamed ndeye audito...</td>\n",
       "      <td>phising</td>\n",
       "      <td>phising</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>subject rates go november refinance  specialis...</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>subject  best sex life hello  boyfriend began ...</td>\n",
       "      <td>medical-sales</td>\n",
       "      <td>medical-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>subject  3   talk thread tabs smanhem ojeffery...</td>\n",
       "      <td>medical-sales</td>\n",
       "      <td>medical-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>subject want penis hard ai   time  cilcking ht...</td>\n",
       "      <td>medical-sales</td>\n",
       "      <td>medical-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>subject life  online pharmacy  drugs direct dr...</td>\n",
       "      <td>medical-sales</td>\n",
       "      <td>medical-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>subject c  ialis  pennies per tablet        hi...</td>\n",
       "      <td>medical-sales</td>\n",
       "      <td>medical-sales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>896 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence           label  \\\n",
       "1144  subject   utf  8  q  take 1     utf  8  q  1 m...   medical-sales   \n",
       "180   subject  dream lifestyle earlene  know actuall...      investment   \n",
       "2069  subject photoshop  windows  office  cheap  bro...  software-sales   \n",
       "1528  subject dr ndeye desk dr  mohamed ndeye audito...         phising   \n",
       "48    subject rates go november refinance  specialis...   insurance-etc   \n",
       "...                                                 ...             ...   \n",
       "1163  subject  best sex life hello  boyfriend began ...   medical-sales   \n",
       "1134  subject  3   talk thread tabs smanhem ojeffery...   medical-sales   \n",
       "655   subject want penis hard ai   time  cilcking ht...   medical-sales   \n",
       "610   subject life  online pharmacy  drugs direct dr...   medical-sales   \n",
       "387   subject c  ialis  pennies per tablet        hi...   medical-sales   \n",
       "\n",
       "                pred  \n",
       "1144   medical-sales  \n",
       "180    medical-sales  \n",
       "2069  software-sales  \n",
       "1528         phising  \n",
       "48     insurance-etc  \n",
       "...              ...  \n",
       "1163   medical-sales  \n",
       "1134   medical-sales  \n",
       "655    medical-sales  \n",
       "610    medical-sales  \n",
       "387    medical-sales  \n",
       "\n",
       "[896 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fasttext\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(data, test_size=0.4)\n",
    "with open('spam-train.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for idx, row in train_set.iterrows():\n",
    "        f.write(\"__label__\" + row.label + \" \" + row.sentence + \"\\n\")\n",
    "model = fasttext.train_supervised(input='spam-train.txt', epoch=25, lr =0.5, wordNgrams=4, loss='hs', dim=50)\n",
    "fastText_df = pd.DataFrame(test_set.sentence)\n",
    "fastText_df['label'] = test_set.label\n",
    "preds = []\n",
    "for sentence in test_set.sentence:\n",
    "    pred = model.predict(sentence)\n",
    "    label = pred[0][0].replace(\"__label__\", \"\")\n",
    "    preds.append(label)\n",
    "test_set['pred'] = preds\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ad44ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8683035714285714"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(test_set[\"label\"], test_set[\"pred\"], average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad505e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.775708923384923"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(test_set[\"label\"], test_set[\"pred\"], average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6741801c-4b03-40d0-8798-17246f7d5745",
   "metadata": {},
   "source": [
    "## Test Unannotated files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "703ced3b-f3df-4e7e-ac54-fc1be496b9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_unannotated = []\n",
    "path = os.getcwd() + \"/enron6/spam\"\n",
    "os.chdir(path)\n",
    "for file in os.listdir():\n",
    "    if file.endswith(\".txt\"):\n",
    "        file_path = f\"{path}/{file}\"\n",
    "        text_unannotated.append(cleaning(str(read_text_file(file_path))))\n",
    "os.chdir(\"../..\")\n",
    "data_unannotated = pd.DataFrame({'sentence':text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f08be47b-ff83-46b5-9ffc-791b5bf939b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject  h  ello dea 54 r home owner  beetcn n...</td>\n",
       "      <td>medical-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject make  171 hello  sent email ago  quali...</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject 96  refinance 2  9  hi would reflnance...</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject 82  refinance today  low 2  9  hey wou...</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject 6  refinance today premium low rate he...</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>subject  2   question soft mult gua msof  ilan...</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>subject  5   question progs mult gua msof  ila...</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>subject  7   talks soft mult gua msof  ilan ge...</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>subject dear sir  interested hi   need softwar...</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>__label__softwaresales subject coreldraw  100 ...</td>\n",
       "      <td>phising</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence            pred\n",
       "0     subject  h  ello dea 54 r home owner  beetcn n...   medical-sales\n",
       "1     subject make  171 hello  sent email ago  quali...   insurance-etc\n",
       "2     subject 96  refinance 2  9  hi would reflnance...   insurance-etc\n",
       "3     subject 82  refinance today  low 2  9  hey wou...   insurance-etc\n",
       "4     subject 6  refinance today premium low rate he...   insurance-etc\n",
       "...                                                 ...             ...\n",
       "2235  subject  2   question soft mult gua msof  ilan...  software-sales\n",
       "2236  subject  5   question progs mult gua msof  ila...  software-sales\n",
       "2237  subject  7   talks soft mult gua msof  ilan ge...  software-sales\n",
       "2238  subject dear sir  interested hi   need softwar...  software-sales\n",
       "2239  __label__softwaresales subject coreldraw  100 ...         phising\n",
       "\n",
       "[2240 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "for sentence in data_unannotated.sentence:\n",
    "    pred = model.predict(sentence)\n",
    "    label = pred[0][0].replace(\"__label__\", \"\")\n",
    "    preds.append(label)\n",
    "data_unannotated['pred'] = preds\n",
    "data_unannotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a55f3943-b952-4e94-9e3b-5224a2b2cdbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medical-sales     1156\n",
       "phising            352\n",
       "software-sales     303\n",
       "investment         173\n",
       "insurance-etc      164\n",
       "sexual              92\n",
       "Name: pred, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_unannotated.pred.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775246b5-459b-4382-9c4c-86a169498304",
   "metadata": {},
   "source": [
    "## Exploring some of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f688427-6b56-43d3-987e-8c467d02da0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject request sadie shansel cater ivortex reticulum incommensurate antipode  assassinate enzyme fabricate cofactor shanty  vise sabdomen polar taken  elapse anthem functionary  curate atlantis pfedora contention avaricious forfeiture tclairvoyant cane jmagnolia lowland kajar  curlew  hawaiian quillwort  oval respected member  winner summer ra e  give way program  please inform since winner offer one time opportunity lower interest r te 3  99 percent  get prize coupon id  2518 thank  valerie mcnally promotion department antisemitic lissajous  converse omission decay fcircumscribe verity  superstitious wallis drier crosswalk  aeolian  ostracism salesgirl dependent crass  defrock  centipede onto gfloodlit dolomitic jdauphine grizzle upstand  agnomen vienna  backspace vanish irresolvable qbarricade redshank  danbury agriculture snifter turpuvdqt eternal  countenance broody arnold scarburetor priory  tmoroccan zgkvuow dog identify transmissible cathedral colloquia sunburnt fcabot franchise yrxprdbz claw  cooley floodlit cranny bedlam anteater daeaddi dexter  anvil euphrates  quaternary bellatrix citron  confidante  oelate ptowel melissa unary  deceitful  twofold  bodice cairo towhead corralled asteria chow rail kinglet boeotian canoga  uruguay cryptanalyze lahore composition proclivity goniometer ovate typographer sicily nasturtium deemphasize ijealousy accelerate sc hzombie centrifugate  confine wgypsy bookbind ypbselg wsubstitute baffin abase spectroscopic joy bicycle  wwzeetcr \n",
      "insurance-etc\n"
     ]
    }
   ],
   "source": [
    "print(data_unannotated.iloc[42].sentence)\n",
    "print(data_unannotated.iloc[42].pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "913fa293-d64a-426e-8b40-e6cfa5745bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject   utf  8  q  might become     utf  8  q  advantageo     utf  8  q  us chap gi     utf  8  q  rl    products used heal erectile dysfunction  well far  famed inability copulate  someone cannot procure  retain  inflexible vertical member suitable intimate action  drugs  appropriate used execution enhancer vantage tablets function two days fabricate physical structure click buy \n",
      "medical-sales\n"
     ]
    }
   ],
   "source": [
    "print(data_unannotated.iloc[1111].sentence)\n",
    "print(data_unannotated.iloc[1111].pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c2377b6-2ea7-4a4c-9a3e-ca656c21d3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject feel great time day summers 80  savings xanax  valium  phentermine  viagra email removal  go  alight impulse ingest impractical corrector beast postpone watershed audition midland stub entendre heinz fragile erickson barrel ymca clairenora provincial ridgepole absorb decelerate santa vertex decathlon posteriori dixon doherty wondrous cycad hawley airstrip especial cornucopia jugginghildebrand otherwise checksumming countersunk picasso laguerre mathematician cambrian invincible ballot brownian lactose nubia statuary cardiac sincere blanc sulfatebaleful eigenvector playwriting malarial nevins northward trickery blowfish impatient arrival cryptanalytic spearmint narbonne friar bathroom waistline cosine dioxidemcgrath wept altair elysee snook gardenia eclipse amorphous mendelevium bestubble honk allay escrow inertance peafowl\n",
      "medical-sales\n"
     ]
    }
   ],
   "source": [
    "print(data_unannotated.iloc[432].sentence)\n",
    "print(data_unannotated.iloc[432].pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1202cd91-0510-4f04-85e4-c3675b273857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject lupe come watch   lube neeeed  let glide priiiiide  make feeeeed  come riiiiiiide       address solute inconvertible earnest message earthmoving frontage alpenstock experiential ordinance graves bufflehead darpa mobcap rodeo puzzle crewman penitentiary brahms inbreed tadpole delouse reciprocal aristocratic militia pet wakeup pence gully holland capo  blacken cutoff middlebury ramify bellboy austere axon ferguson adolph affable scriptural dead neve closeup passage tombstone refer sud amazon circuit clapboard chipboard apperception ama pheasant acyclic canis marion nelsen wave debauch thoreau fabricate bronco bebop burgundian aliquot sari automaton  \n",
      "sexual\n"
     ]
    }
   ],
   "source": [
    "sexual = data_unannotated[data_unannotated['pred'] == 'sexual']\n",
    "print(sexual.iloc[12].sentence)\n",
    "print(sexual.iloc[12].pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ddca6600-0eff-4bee-a128-42e2728d6b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject doctor contact  medicaldirectory  physiciansguid 7  000 hospitals  25  000 nursing homes 400  000 doctors united states health care database united states healthcare database comprehensive new product offered exclusively limited  time basis  complete database includes hospitals  hmo   group medical practices  nursing homes  physicians country  rapidly  changing industry  current healthcare information invaluable resource businesses organizations  united states healthcare database includes comprehensive information 7  000 hospitals  25  000 nursing homes 400  000 doctors mention hmos group medical practices  extensive reliable mailing list database key decision makers health care market  imagine increase marketing sales effectiveness made possible targeting key contacts name  reaching right decision maker critical success direct marketing campaigns  product  record indexed features name  address  phone fax  database available excel format cd rom  designed mailing lists merges  data selected state criteria type practice  used unlimited basis  introductory offer  cost completely new database  available exclusively cd  rom   575  00  reg   1  495   annual subscription  includes six editions  available  825  reg   2  995  order united states health care database  c   please complete information fax number 1  905  751  0199  tel  905  751  0919     would like order united states health care database   575   please invoice    would like annual subscription  six editions  825   please invoice  name  title  organization  address  city  postal  tel  fax  e  mail  order united states health care database  c   please complete information fax 1  905  751  0199  tel  1  905  751  0919  infosource group companies leading information publishing firm offices throughout north america europe  removed database please follow link  http    notinuse  biz  takeoff  takeoff  html \n",
      "software-sales\n"
     ]
    }
   ],
   "source": [
    "software = data_unannotated[data_unannotated['pred'] == 'software-sales']\n",
    "print(software.iloc[9].sentence)\n",
    "print(software.iloc[9].pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "028e51ed-d6be-4dff-a37d-f8eae1ccaa7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject stock profiier belanger  continue  important  expected  u c p  wi   large pr campaign next 10 days positive news expected  watch  jump board whiie stock beiow  1  huge promo weekend expected expect soar monday  tuesday next week  jump today  voice internet protoco   voip  service goes live symbol   u c p  current price   0  28 10 days target price   1  25 3 months target price   1  66  u c p  currentiy trading  0  28 headed  1  25 company reieased ground breaking news voip division   aithough would argue voip stil  maturing  corporate users extremeiy interested impiementing technoiogy  creating exponential growth  within last four years  voip minutes increased  ess 0  5 2 percent outbound international calis  according research telegeography  additionally  predictions size market vary    ied business inte   igence projecting voip market grow  3  7 bi   ion 2000  12  3 billion 2006  synergy research projecting voip equipment market grow  13  3 biliion 2005  uauthorize corporation e  business hoiding company builds acquires multiple websites  software titles   e  commerce soiutions  everage internet maximize success e  business operations  uauthorize also results  oriented marketer technology products  services  comprehensive portfoiio products  services  uauthorize attracts highly qualified audience technology product service buyers  company  successful business model based muitipie growth drivers  inciuding growth technology products service  cross  seliing additiona  products new affiliate signings  profile  uauthorize corp symbol   u c p  current price   0  28 rating  undervaiued beiieve speculative near term target price   1  25 believe speculative long term target price   1  50 voice internet protocol  voip  service goes live beiieve best pick since march 2004   real company real products stock headed                information within email contains  forward looking statements  within meaning section 27 securities act 1933 section 21 b securities exchange act 1934  statements express involve discussions respect predictions  goals  expectations  beliefs  plans  projections  objectives  assumptions future events performance statements historical fact may  forward looking statements   forward looking statements based expectations  estimates projections time statements made involve number risks uncertainties could cause actual results events differ materially presently anticipated  forward looking statements action may identified use words   projects    foresee    expects    estimates    believes    understands      part   anticipates   statements indicating certain actions  may    could    might  occur  information provided within email pertaining investing  stocks  securities must understood information provided investment advice  advise readers subscribers seek advice registered professional securities representative deciding trade stocks featured within email  none material within report shall construed kind investment advice  please mind interpretation witer newsletter news published company represent company official statement fact may differ real meaning news release meant say  ple  se  news release judge details  compliance section 17  b   disclose holding u c p shares prior publication report  aware inherent conflict interest resulting holdings due intent profit liquidation shares  shares may sold time  even positive statements made regarding company  since shares  inherent conflict interest statements opinions  readers publication cautioned place undue reliance forward  looking statements  based certain assumptions expectations involving various risks uncertainties  could cause results differ materially set forth forward  looking statements  please advised nothing within email shall constitute solicitation offer b u sell security mentioned herein  newsletter neither registered investment advisor affiliated broker dealer  statements made express opinion treated  may  b u sell securities mentioned time  report includes forward  looking statements within meaning private securities litigation reform act 1995  statements may include terms  expect    believe    may       move    undervalued   intend  similar terms  newsletter paid  12500 third party send report  please due diligence investing profiled company  may lose money investing penny stocks \n",
      "investment\n"
     ]
    }
   ],
   "source": [
    "investment = data_unannotated[data_unannotated['pred'] == 'investment']\n",
    "print(investment.iloc[29].sentence)\n",
    "print(investment.iloc[29].pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "642f3784-30a6-40d1-be57-3c9a0eb7cacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject winning notification  lottery coordinator  international promotions  prize award department dear winner  results category   draws congratulations bring notice  results first category draws lucky strike lottery uk  happy inform emerged winner first category  part promotional draws  draws held day prior notification results officially announced  participants selected computer ballot system drawn 2  500  000 names  email addresses individuals companies africa  america  asia  australia  europe  middle east  oceania part international promotions program   company  attached ticket number 6422  5  486  serial number 59  18 drew lucky numbers 33  92  78  05  18  consequently first category  therefore awarded lump sum pay  6  500  000  six million  five hundred thousand great britain pounds   winning payout category winners  total prize money  13  000  000 shared among 2 winners category  congratulations  fund deposited transfer agents cash change uk ltd insured name  best interest also avoid mix numbers names kind  request keep entire details award strictly public notice process transferring claims completed  funds remitted account  part security protocol avoid double claiming unscrupulous acts participants  non participants program  also wish bring notice end year premium stakes draw stand chance winning  50 million  hope part prize participate  please contact claims agent immediately due processing remittance prize money designated account choice  mr  andrew young  foreign department manager  cash change uk ltd foreign service number   88216 4665 5376 tel   44 2070600695 fax   44 2079002649 advised contact agents email fax within week receiving notice  failure may warrant disqualification  note  easy reference identification  find reference batch numbers  remember quote numbers every one correspondences claims agent  reference number  lsluk  2031  8161  04 batch number  r 3  312  59 congratulations staff thank part promotions program  sincerely  lottery coordinator  lucky strike lottery uk 12 bridge street  staines middlesex twl 8 4 tp uk n  b  breach confidentiality part winners result disqualification  please contact claims agent immediately  mail sent webmail service php  nuke powered site  http    www  teamnitroassassins  com\n",
      "phising\n"
     ]
    }
   ],
   "source": [
    "phising = data_unannotated[data_unannotated['pred'] == 'phising']\n",
    "print(phising.iloc[21].sentence)\n",
    "print(phising.iloc[21].pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c21451e-a617-41c2-864a-130091c8ae52",
   "metadata": {},
   "source": [
    "## Seems good at predicting these unannotated files, but is it still overfitting to only this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "181bcbc3-b1d7-43dc-9f03-a72643b946cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__software-sales',\n",
       "  '__label__insurance-etc',\n",
       "  '__label__medical-sales',\n",
       "  '__label__phising',\n",
       "  '__label__insuranceetc'),\n",
       " array([0.47605869, 0.47433549, 0.02369787, 0.0191186 , 0.00666779]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"congrats you have won 1 million usd in the lottery from usa. please click here to earn your prize\", k = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c8090c-8310-47ed-b3b8-1f245e71d926",
   "metadata": {},
   "source": [
    "Wrong label, phising is all the way at the 4th contender!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98f384a2-bb0a-470a-aeef-90cc392d99d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__medical-sales',\n",
       "  '__label__sexual',\n",
       "  '__label__medicalsales',\n",
       "  '__label__software-sales',\n",
       "  '__label__insurance-etc'),\n",
       " array([0.77838385, 0.1330519 , 0.03946874, 0.02377219, 0.01588757]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"want to watch webcams of young teen girls to get your affair on today in bed\", k = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d140089b-498a-44b7-a3aa-15799316a539",
   "metadata": {},
   "source": [
    "Another wrong label, very confident this is medical???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
