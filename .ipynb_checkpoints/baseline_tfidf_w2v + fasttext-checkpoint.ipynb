{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adbbc2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lorraine/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/lorraine/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/lorraine/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject take advantage low interest  rates  no...</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject lowest rate us history sound  let 6000...</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject application pre  approved monday oct 1...</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject final offer wed  29 sep 2004 19  16  0...</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject application confirmation sun  14 nov 2...</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>subject popular software low low prices  bury ...</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>subject clean ur computer 3 ey 85  chance comp...</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>subject software incredibly low prices  73  lo...</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>subject latest qem software available  low pri...</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>subject cnet reviews  results favorite program...</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2240 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence           label\n",
       "0     subject take advantage low interest  rates  no...   insurance-etc\n",
       "1     subject lowest rate us history sound  let 6000...   insurance-etc\n",
       "2     subject application pre  approved monday oct 1...   insurance-etc\n",
       "3     subject final offer wed  29 sep 2004 19  16  0...   insurance-etc\n",
       "4     subject application confirmation sun  14 nov 2...   insurance-etc\n",
       "...                                                 ...             ...\n",
       "2235  subject popular software low low prices  bury ...  software-sales\n",
       "2236  subject clean ur computer 3 ey 85  chance comp...  software-sales\n",
       "2237  subject software incredibly low prices  73  lo...  software-sales\n",
       "2238  subject latest qem software available  low pri...  software-sales\n",
       "2239  subject cnet reviews  results favorite program...  software-sales\n",
       "\n",
       "[2240 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "  \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import re\n",
    "def cleaning(sentence):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = re.sub(r'[^\\w\\s]', '', sentence.lower()).replace(\"\\n\", \" \").split(\" \")\n",
    "    cleaned = [token for token in tokens if token not in stop_words]\n",
    "    return \" \".join(cleaned)\n",
    "labels = [\"insurance-etc\",\"investment\", \"medical-sales\", \"phising\", \"sexual\", \"software-sales\"]\n",
    "text = []\n",
    "classes = []\n",
    "for label in labels:\n",
    "    path = \"/Users/lorraine/Desktop/Spam_Filter/Annotated/\"+label\n",
    "  \n",
    "    os.chdir(path)\n",
    "  \n",
    "    def read_text_file(file_path):\n",
    "        with open(file_path, 'r', encoding='ISO-8859-1') as f:\n",
    "            return f.read()\n",
    "      \n",
    "    for file in os.listdir():\n",
    "    \n",
    "        if file.endswith(\".txt\"):\n",
    "            file_path = f\"{path}/{file}\"\n",
    "            text.append(cleaning(str(read_text_file(file_path))))\n",
    "            classes.append(label)\n",
    "\n",
    "data = pd.DataFrame({'sentence':text, 'label':classes})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3444b1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "932b7945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(word):\n",
    "    sentence = data['sentence']\n",
    "    idf = np.log(len(sentence)/sentence.str.contains(word).sum())\n",
    "    result = []\n",
    "    for i in range(len(sentence)):\n",
    "        tf = sentence.iloc[i].count(word)/(len(sentence.iloc[i]))\n",
    "        result.append(tf*idf)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7bf0907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>insurance-etc</th>\n",
       "      <th>investment</th>\n",
       "      <th>medical-sales</th>\n",
       "      <th>phising</th>\n",
       "      <th>sexual</th>\n",
       "      <th>software-sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.032326</td>\n",
       "      <td>0.011919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007120</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.057216</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012817</td>\n",
       "      <td>0.006168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2240 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      insurance-etc  investment  medical-sales   phising    sexual  \\\n",
       "0          0.032326    0.011919       0.000000  0.000000  0.007120   \n",
       "1          0.057216    0.003807       0.000000  0.000000  0.000000   \n",
       "2          0.015567    0.000000       0.001333  0.000000  0.000000   \n",
       "3          0.012817    0.006168       0.000000  0.003680  0.000000   \n",
       "4          0.016901    0.000000       0.002614  0.000000  0.001915   \n",
       "...             ...         ...            ...       ...       ...   \n",
       "2235       0.000000    0.003564       0.000000  0.000000  0.000000   \n",
       "2236       0.000000    0.000000       0.003047  0.000000  0.000000   \n",
       "2237       0.000000    0.003709       0.002111  0.000000  0.000000   \n",
       "2238       0.000000    0.002460       0.000000  0.010794  0.000000   \n",
       "2239       0.000000    0.003728       0.000000  0.002504  0.000000   \n",
       "\n",
       "      software-sales  \n",
       "0           0.000000  \n",
       "1           0.000000  \n",
       "2           0.000000  \n",
       "3           0.022436  \n",
       "4           0.000000  \n",
       "...              ...  \n",
       "2235        0.008678  \n",
       "2236        0.000000  \n",
       "2237        0.009031  \n",
       "2238        0.077445  \n",
       "2239        0.014193  \n",
       "\n",
       "[2240 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "f = open('/Users/lorraine/Desktop/Spam_Filter/seedwords.json')\n",
    "seeds = json.load(f)\n",
    "result = pd.DataFrame()\n",
    "for key, value in seeds.items():\n",
    "    df = pd.DataFrame()\n",
    "    for w in value:\n",
    "        df[w] = tfidf(w)\n",
    "    result[key] = df.sum(axis = 1)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80c53b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject take advantage low interest  rates  no...</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject lowest rate us history sound  let 6000...</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject application pre  approved monday oct 1...</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject final offer wed  29 sep 2004 19  16  0...</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject application confirmation sun  14 nov 2...</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>subject popular software low low prices  bury ...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>subject clean ur computer 3 ey 85  chance comp...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>medical-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>subject software incredibly low prices  73  lo...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>subject latest qem software available  low pri...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>subject cnet reviews  results favorite program...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2240 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence           label  \\\n",
       "0     subject take advantage low interest  rates  no...   insurance-etc   \n",
       "1     subject lowest rate us history sound  let 6000...   insurance-etc   \n",
       "2     subject application pre  approved monday oct 1...   insurance-etc   \n",
       "3     subject final offer wed  29 sep 2004 19  16  0...   insurance-etc   \n",
       "4     subject application confirmation sun  14 nov 2...   insurance-etc   \n",
       "...                                                 ...             ...   \n",
       "2235  subject popular software low low prices  bury ...  software-sales   \n",
       "2236  subject clean ur computer 3 ey 85  chance comp...  software-sales   \n",
       "2237  subject software incredibly low prices  73  lo...  software-sales   \n",
       "2238  subject latest qem software available  low pri...  software-sales   \n",
       "2239  subject cnet reviews  results favorite program...  software-sales   \n",
       "\n",
       "          prediction  \n",
       "0      insurance-etc  \n",
       "1      insurance-etc  \n",
       "2      insurance-etc  \n",
       "3     software-sales  \n",
       "4      insurance-etc  \n",
       "...              ...  \n",
       "2235  software-sales  \n",
       "2236   medical-sales  \n",
       "2237  software-sales  \n",
       "2238  software-sales  \n",
       "2239  software-sales  \n",
       "\n",
       "[2240 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"prediction\"] = result.idxmax(1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ba42050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# micro and macro F1 using tf-idf\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b013429c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6924107142857143"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(data[\"label\"], data[\"prediction\"], average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f00df97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666147160818625"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(data[\"label\"], data[\"prediction\"], average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb39d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ef2f1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "def preprocessing(sentence):\n",
    "    tokens = sentence.split(\" \")\n",
    "    return [token for token in tokens if token!=\"\" and token != \" \"]\n",
    "features = data[\"sentence\"].apply(preprocessing)\n",
    "model = Word2Vec(sentences=features, size=50, window=5, min_count=1, workers=4)\n",
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "600ed801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33331433, 49235200)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save(\"word2vec.model\")\n",
    "model = Word2Vec.load(\"word2vec.model\")\n",
    "model.train(features, total_examples=len(data), epochs=100)\n",
    "#vector = model.wv[\"atheism\"]\n",
    "#vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dd44e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors_per_label(filename):\n",
    "    f = open(filename)\n",
    "    seeds = json.load(f)\n",
    "    vector_per_label = []\n",
    "    for key, value in seeds.items():\n",
    "        lst = []\n",
    "        for w in value:\n",
    "            lst.append(model.wv[w])\n",
    "        arr = np.asarray(lst)\n",
    "        total = np.average(arr, axis=0)\n",
    "        vector_per_label.append(total)\n",
    "    return vector_per_label\n",
    "vector_per_label = get_vectors_per_label('/Users/lorraine/Desktop/Spam_Filter/seedwords.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f18640f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e7bcc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_per_doc(feature):\n",
    "    vector_per_doc = []\n",
    "    for feat in feature:\n",
    "        lst = []\n",
    "        for w in feat:\n",
    "            lst.append(model.wv[w])\n",
    "        arr = np.asarray(lst)\n",
    "        total = np.average(arr, axis=0)\n",
    "        vector_per_doc.append(total)\n",
    "    return vector_per_doc\n",
    "vector_per_doc = get_vector_per_doc(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "988a06a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2240"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector_per_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a89c5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d97daeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/Users/lorraine/Desktop/Spam_Filter/seedwords.json')\n",
    "seeds = json.load(f)\n",
    "from numpy.linalg import norm\n",
    "def predict_word2vec(vector_per_doc, vector_per_label):\n",
    "    predictions = []\n",
    "    labels = list(seeds.keys())\n",
    "    for doc in vector_per_doc:\n",
    "        cosine = []\n",
    "        for label in vector_per_label:\n",
    "            cosine.append(np.dot(doc,label)/(norm(doc)*norm(label)))\n",
    "        max_value = max(cosine)\n",
    "        max_index = cosine.index(max_value)\n",
    "        predictions.append(labels[max_index])\n",
    "    return predictions   \n",
    "prediction_word2vec = predict_word2vec(vector_per_doc, vector_per_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e804645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prediction_word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject take advantage low interest  rates  no...</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject lowest rate us history sound  let 6000...</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject application pre  approved monday oct 1...</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject final offer wed  29 sep 2004 19  16  0...</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject application confirmation sun  14 nov 2...</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>insurance-etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>subject popular software low low prices  bury ...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>medical-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>subject clean ur computer 3 ey 85  chance comp...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>medical-sales</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>subject software incredibly low prices  73  lo...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>medical-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>subject latest qem software available  low pri...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>subject cnet reviews  results favorite program...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2240 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence           label  \\\n",
       "0     subject take advantage low interest  rates  no...   insurance-etc   \n",
       "1     subject lowest rate us history sound  let 6000...   insurance-etc   \n",
       "2     subject application pre  approved monday oct 1...   insurance-etc   \n",
       "3     subject final offer wed  29 sep 2004 19  16  0...   insurance-etc   \n",
       "4     subject application confirmation sun  14 nov 2...   insurance-etc   \n",
       "...                                                 ...             ...   \n",
       "2235  subject popular software low low prices  bury ...  software-sales   \n",
       "2236  subject clean ur computer 3 ey 85  chance comp...  software-sales   \n",
       "2237  subject software incredibly low prices  73  lo...  software-sales   \n",
       "2238  subject latest qem software available  low pri...  software-sales   \n",
       "2239  subject cnet reviews  results favorite program...  software-sales   \n",
       "\n",
       "          prediction prediction_word2vec  \n",
       "0      insurance-etc       insurance-etc  \n",
       "1      insurance-etc       insurance-etc  \n",
       "2      insurance-etc       insurance-etc  \n",
       "3     software-sales       insurance-etc  \n",
       "4      insurance-etc       insurance-etc  \n",
       "...              ...                 ...  \n",
       "2235  software-sales       medical-sales  \n",
       "2236   medical-sales      software-sales  \n",
       "2237  software-sales       medical-sales  \n",
       "2238  software-sales      software-sales  \n",
       "2239  software-sales      software-sales  \n",
       "\n",
       "[2240 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"prediction_word2vec\"] = prediction_word2vec\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f8b4d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6017857142857143"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# micro and macro F1 using word2vec\n",
    "metrics.f1_score(data[\"label\"], data[\"prediction_word2vec\"], average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96cbe228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6208801067340314"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(data[\"label\"], data[\"prediction_word2vec\"], average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "163c1c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5962483251451541"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data[\"prediction_word2vec\"] == data[\"label\"])/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7559151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  29150\n",
      "Number of labels: 6\n",
      "Progress: 100.0% words/sec/thread: 1614532 lr:  0.000000 avg.loss:  0.027763 ETA:   0h 0m 0s100.0% words/sec/thread: 1614554 lr: -0.000010 avg.loss:  0.027763 ETA:   0h 0m 0s\n",
      "/var/folders/gr/mx83vpvn7z713f1dzv81v63r0000gn/T/ipykernel_7355/477358470.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_set['pred'] = preds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prediction_word2vec</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>subject reviving sex lives millions online dru...</td>\n",
       "      <td>medical-sales</td>\n",
       "      <td>sexual</td>\n",
       "      <td>medical-sales</td>\n",
       "      <td>medical-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>subject peak performance longz capsules featur...</td>\n",
       "      <td>medical-sales</td>\n",
       "      <td>sexual</td>\n",
       "      <td>sexual</td>\n",
       "      <td>medical-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>subject  4   talk pills spu r  th ewe saf twa ...</td>\n",
       "      <td>medical-sales</td>\n",
       "      <td>medical-sales</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>medical-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>subject fwd  software download update os  look...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>subject   iagra  113  cialis  113  llp 1 tor  ...</td>\n",
       "      <td>medical-sales</td>\n",
       "      <td>medical-sales</td>\n",
       "      <td>medical-sales</td>\n",
       "      <td>medical-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>subject summer macromedia  mlcros 0 ft  symann...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>subject refill notification ref  wx  339097195...</td>\n",
       "      <td>medical-sales</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>sexual</td>\n",
       "      <td>medical-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>subject investors  microcap profiie sandoval  ...</td>\n",
       "      <td>investment</td>\n",
       "      <td>investment</td>\n",
       "      <td>investment</td>\n",
       "      <td>investment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>subject lose weight  new weightloss loses 19  ...</td>\n",
       "      <td>medical-sales</td>\n",
       "      <td>sexual</td>\n",
       "      <td>insurance-etc</td>\n",
       "      <td>medical-sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>subject warez cd  microsoft windows xp profess...</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "      <td>software-sales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>896 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence           label  \\\n",
       "427   subject reviving sex lives millions online dru...   medical-sales   \n",
       "476   subject peak performance longz capsules featur...   medical-sales   \n",
       "1275  subject  4   talk pills spu r  th ewe saf twa ...   medical-sales   \n",
       "2210  subject fwd  software download update os  look...  software-sales   \n",
       "1099  subject   iagra  113  cialis  113  llp 1 tor  ...   medical-sales   \n",
       "...                                                 ...             ...   \n",
       "1984  subject summer macromedia  mlcros 0 ft  symann...  software-sales   \n",
       "583   subject refill notification ref  wx  339097195...   medical-sales   \n",
       "232   subject investors  microcap profiie sandoval  ...      investment   \n",
       "1284  subject lose weight  new weightloss loses 19  ...   medical-sales   \n",
       "2049  subject warez cd  microsoft windows xp profess...  software-sales   \n",
       "\n",
       "          prediction prediction_word2vec            pred  \n",
       "427           sexual       medical-sales   medical-sales  \n",
       "476           sexual              sexual   medical-sales  \n",
       "1275   medical-sales      software-sales   medical-sales  \n",
       "2210  software-sales      software-sales  software-sales  \n",
       "1099   medical-sales       medical-sales   medical-sales  \n",
       "...              ...                 ...             ...  \n",
       "1984  software-sales      software-sales  software-sales  \n",
       "583   software-sales              sexual   medical-sales  \n",
       "232       investment          investment      investment  \n",
       "1284          sexual       insurance-etc   medical-sales  \n",
       "2049  software-sales      software-sales  software-sales  \n",
       "\n",
       "[896 rows x 5 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fasttext\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(data, test_size=0.4)\n",
    "with open('spam-train.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for idx, row in train_set.iterrows():\n",
    "        f.write(\"__label__\" + row.label + \" \" + row.sentence + \"\\n\")\n",
    "model = fasttext.train_supervised(input='spam-train.txt', epoch=500, lr=0.5, wordNgrams=3, loss='hs', dim=50)\n",
    "fastText_df = pd.DataFrame(test_set.sentence)\n",
    "fastText_df['label'] = test_set.label\n",
    "preds = []\n",
    "for sentence in test_set.sentence:\n",
    "    pred = model.predict(sentence)\n",
    "    #try:\n",
    "    label = pred[0][0].replace(\"__label__\", \"\")\n",
    "    preds.append(label)\n",
    "    #except:\n",
    "    #    # cant predict? Predict most common label \n",
    "    #    preds.append('medical-sales')\n",
    "test_set['pred'] = preds\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e2abd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__label__medical-sales', '__label__phising', '__label__software-sales', '__label__investment', '__label__insurance-etc', '__label__sexual']\n"
     ]
    }
   ],
   "source": [
    "print(model.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ad44ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9073660714285715"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(test_set[\"label\"], test_set[\"pred\"], average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ad505e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8606963390783315"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(test_set[\"label\"], test_set[\"pred\"], average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a1b777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56f4543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
